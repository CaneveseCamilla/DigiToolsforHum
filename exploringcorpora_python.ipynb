{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46360041",
   "metadata": {},
   "source": [
    "# Our first Notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82624029",
   "metadata": {},
   "source": [
    "## 1. Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab097b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/hp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a6eb9",
   "metadata": {},
   "source": [
    "### 1.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b6057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7443d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc08166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(data_dir + 'Book1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de161007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69525db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bk1 = data_dir + 'Book1.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f58c2e",
   "metadata": {},
   "source": [
    "### 1.2 Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8548aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bk1) as f:\n",
    "    bk1_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e843fc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bk1_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d159c",
   "metadata": {},
   "source": [
    "This is the number of characters. No tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "445c429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BOY WHO LIVED \n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, \n",
      "were proud to say that they were perfectly normal, \n",
      "thank you very much. They were the last people you’d \n",
      "expect to be involved in anythi\n"
     ]
    }
   ],
   "source": [
    "print(bk1_text[:210])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09caa68",
   "metadata": {},
   "source": [
    "## 2. Work with text and `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c09d05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e67d1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528bf1d",
   "metadata": {},
   "source": [
    "### 2.1 Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f18758",
   "metadata": {},
   "source": [
    "We need some functions that do tokenization. There is a submodule of nltk called *tokenize*. \n",
    "https://www.nltk.org/api/nltk.tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b568ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e08cfd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/camillacanevese/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b53b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bk1_toks = word_tokenize(bk1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7489e6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449564"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bk1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1ec1a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101221"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bk1_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3978aad0",
   "metadata": {},
   "source": [
    "Let's inspect our tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9257ba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'blonde',\n",
       " 'and',\n",
       " 'had',\n",
       " 'nearly',\n",
       " 'twice',\n",
       " 'the',\n",
       " 'usual',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'neck',\n",
       " ',',\n",
       " 'which',\n",
       " 'came',\n",
       " 'in',\n",
       " 'very',\n",
       " 'useful',\n",
       " 'as',\n",
       " 'she',\n",
       " 'spent']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk1_toks[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9ec61",
   "metadata": {},
   "source": [
    "### 2.2 Corpus readers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34a7eb2",
   "metadata": {},
   "source": [
    "NLTK corpus readers. The modules in this package provide functions that can be used to read corpus fileids in a variety of formats. These functions can be used to read both the corpus fileids that are distributed in the NLTK corpus package, and corpus fileids that are part of external corpora.\n",
    "https://www.nltk.org/api/nltk.corpus.reader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b5b6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbb151f",
   "metadata": {},
   "source": [
    "*PlaintextCorpusReader*: A reader for plaintext corpora whose documents are divided into categories based on their file identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e632141",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_corpus = PlaintextCorpusReader(data_dir, fileids= r'.*\\.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b3238",
   "metadata": {},
   "source": [
    "We must specify the *root* (in our case *data_dir*) and a fileID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81d0aa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Book1.txt',\n",
       " 'Book2.txt',\n",
       " 'Book3.txt',\n",
       " 'Book4.txt',\n",
       " 'Book5.txt',\n",
       " 'Book6.txt',\n",
       " 'Book7.txt']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_corpus.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef34af",
   "metadata": {},
   "source": [
    "Here, we are just accessing all files of the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c06ce772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE RIDDLE HOUSE \n",
      "\n",
      "The villagers of Little Hangleton still called it “the \n",
      "Riddle House,” eve\n"
     ]
    }
   ],
   "source": [
    "print(hp_corpus.raw(fileids = 'Book4.txt')[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72770bbe",
   "metadata": {},
   "source": [
    "In this case, the command print the corpus as a *string of characters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63bfb1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Peacocks',\n",
       " '...”',\n",
       " 'Yaxley',\n",
       " 'thrust',\n",
       " 'his',\n",
       " 'wand',\n",
       " 'back',\n",
       " 'under',\n",
       " 'his',\n",
       " 'cloak',\n",
       " 'with',\n",
       " 'a',\n",
       " 'snort',\n",
       " '.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_corpus.sents(fileids = 'Book7.txt')[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90b1f9",
   "metadata": {},
   "source": [
    "In this case it returns the list of sentences, that are represented as list of tokens (*list of a list*) of our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75031b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84352"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_corpus.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eae6641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15193"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_corpus.sents(fileids = 'Book7.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87cd2291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr',\n",
       " '.',\n",
       " 'Dursley',\n",
       " 'gave',\n",
       " 'himself',\n",
       " 'a',\n",
       " 'little',\n",
       " 'shake',\n",
       " 'and',\n",
       " 'put',\n",
       " 'the',\n",
       " 'cat',\n",
       " 'out',\n",
       " 'of',\n",
       " 'his',\n",
       " 'mind',\n",
       " '.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_corpus.sents(fileids = 'Book1.txt')[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9971f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_words = hp_corpus.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c54452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1396620"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hp_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd1878f",
   "metadata": {},
   "source": [
    "Here, we are asking for a list of token regardless the token division: a list of all the individual units or elements that make up the text, without concern for how those units are divided or segmented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9831bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'sign',\n",
       " 'of',\n",
       " 'something',\n",
       " 'peculiar',\n",
       " '—',\n",
       " 'a',\n",
       " 'cat',\n",
       " 'reading',\n",
       " 'a',\n",
       " 'map',\n",
       " '.',\n",
       " 'For',\n",
       " 'a',\n",
       " 'second']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_words[500:515]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c0d47",
   "metadata": {},
   "source": [
    "### 2.3 Word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c9467",
   "metadata": {},
   "source": [
    "I want to count words, but before that, I want to lowercase everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "620c9ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harry potter'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Harry Potter'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "832dffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_lower = [tok.lower() for tok in hp_corpus.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fb1cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5354328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(toks_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0161edd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18215"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['harry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64046949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['knew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4542f966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21089"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a75444",
   "metadata": {},
   "source": [
    "How to know which are the most frequent types in our corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8456bc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 74288),\n",
       " ('.', 60720),\n",
       " ('the', 51927),\n",
       " ('“', 36869),\n",
       " ('’', 34270),\n",
       " ('and', 27666),\n",
       " ('to', 26907),\n",
       " ('he', 22223),\n",
       " ('of', 21899),\n",
       " ('a', 21094),\n",
       " ('harry', 18215),\n",
       " ('was', 15646),\n",
       " ('s', 14845),\n",
       " ('you', 14657),\n",
       " ('it', 14572),\n",
       " ('said', 14491),\n",
       " ('his', 14289),\n",
       " ('i', 13492),\n",
       " ('in', 12686),\n",
       " (',”', 11502)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177380fe",
   "metadata": {},
   "source": [
    "Here, we are also taking into account *punctuation* and *function words*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc3172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bc8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
